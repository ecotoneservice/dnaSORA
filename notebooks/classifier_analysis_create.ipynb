{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import torch \n",
    "import gc\n",
    "import plotly.graph_objects as go\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms.v2 import PILToTensor,Compose\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import re\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "from functools import partial, reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import panel as pn\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from holoviews import dim, opts\n",
    "\n",
    "hv.extension(\"plotly\")\n",
    "pn.extension(\"plotly\")\n",
    "pn.extension('tabulator', theme='dark')\n",
    "pn.config.theme = 'dark'\n",
    "hv.renderer('plotly').theme = 'dark'\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.models.unified_classifier import ClassifierModelPipeline, evaluate_unified_classifier_model, predictDenoise, predictCLS, ClassificationHeadDummy\n",
    "from src.models.conv_classifier import ConvChromoClassifier, ConvPredictCLS\n",
    "from src.models.denoiser import DenoiserModelPipeline, DenoiserModel, get_forward_diffusion_params, forward_add_noise\n",
    "from src.md import MDDataset, generate_phases_for_dense_validation, MDDenseSet, MDLoadable, MDDense, MDDensePhaseData\n",
    "from src.preprocessing import ChromoDataContainer, ChromoData\n",
    "\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook loads all trained classification models, evaluate them against dense MD and RD \n",
    "# and saves the results to a pickle file for future parsing and visualization\n",
    "\n",
    "# Loading DenseRD\n",
    "chrom_data = ChromoDataContainer.load_from_pkl()\n",
    "\n",
    "# TODO: Split MD and DenseD to separatte notebooks\n",
    "# 1) MD generates source for Dense MD\n",
    "# 2) DenseD generates Both Dense MD and Dense RD\n",
    "distiled_real_mu = generate_phases_for_dense_validation(chrom_data.gausians, do_real_mu=True)\n",
    "distiled_real_lowess = generate_phases_for_dense_validation(chrom_data.gausians, do_real_mu=False)\n",
    "distiled_mock_mu = MDLoadable.load(\n",
    "    config_name=\"dataset_128_128_784_classifier_control_set_mu\",\n",
    "    config_folder=\"../configs/MDDense\",\n",
    "    dataset_folder=\"../data/MDDense\",\n",
    "    dataset_cls=MDDenseSet)\n",
    "print(f\"Len of distiled_mock_mu: {len(distiled_mock_mu)}\")\n",
    "distiled_mock_lowess = MDLoadable.load(\n",
    "    config_name=\"dataset_128_128_784_classifier_control_set_lowess\",\n",
    "    config_folder=\"../configs/MDDense\",\n",
    "    dataset_folder=\"../data/MDDense\",\n",
    "    dataset_cls=MDDenseSet)\n",
    "print(f\"Len of distiled_mock_lowess: {len(distiled_mock_lowess)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a test of a BOOST algorithm from a paper \"SHOREmap v3.0: Fast and Accurate Identifi cation of Causal Mutations from Forward Genetic Screens\"\n",
    "\n",
    "def calculate_boost_value(probabilities, window_size=50):\n",
    "\n",
    "    def boost_value(obs_theta, target_theta=0.997):\n",
    "        return 1 / abs(1 - max(target_theta, 1-target_theta) / \n",
    "                      max(obs_theta, 1-obs_theta))\n",
    "    \n",
    "    # Calculate mean probabilities in sliding windows\n",
    "    theta_obs = np.array([np.mean(probabilities[i:i+window_size]) \n",
    "                          for i in range(len(probabilities) - window_size)])\n",
    "    \n",
    "    # Calculate boost values for each window\n",
    "    boost_values = np.array([boost_value(theta) for theta in theta_obs])\n",
    "    \n",
    "    # Find peak location (adding window_size//2 to account for convolution)\n",
    "    # peak_location = np.argmax(boost_values) + window_size//2\n",
    "    \n",
    "    peak_location = np.argmax(boost_values)\n",
    "    print(f\"Peak location: {peak_location}, len of prob: {len(probabilities)}, window_size: {window_size}, len of boost_values: {len(boost_values)}, len of theta_obs: {len(theta_obs)}\")\n",
    "    peak_location = peak_location + window_size//2\n",
    "    \n",
    "    return boost_values, peak_location\n",
    "\n",
    "real_mus = []\n",
    "for record in chrom_data.gausians:\n",
    "    if record.m_index:\n",
    "        real_mus.append(record)\n",
    "\n",
    "for record in real_mus:\n",
    "    print(\"=====================================\")\n",
    "    probabilities = record.array['Gxx_ratio'].values\n",
    "    boost_values, peak_location = calculate_boost_value(probabilities, window_size=500)\n",
    "    \n",
    "    pos_peak = record.array['POS'].iloc[peak_location]\n",
    "    pos_real = record.array['POS'].iloc[record.m_index]\n",
    "    accuracy = 100 * (1 - abs(peak_location-record.m_index) / len(probabilities))\n",
    "    \n",
    "    print(f\"G number: {record.g_number}\")\n",
    "    print(f\"Peak location: {peak_location}\")\n",
    "    print(f\"POS on boost location: {pos_peak}\")\n",
    "    print(f\"Real POS: {pos_real}\")\n",
    "    print(f\"Delta MB: {abs(pos_peak-pos_real)/1e6:.3f}\")\n",
    "    print(f\"Accuracy %: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated evaluator for Unified classifier with Linear and Attention heads\n",
    "\n",
    "configs_dir = '../configs/classifier'\n",
    "configs = os.listdir(configs_dir)\n",
    "\n",
    "print(f\"Found {len(configs)} configs\")\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    \n",
    "pipelines = []\n",
    "\n",
    "for config in tqdm(configs):\n",
    "    print(\"=====================================\")\n",
    "    classifierModelPipeline = ClassifierModelPipeline.load(config, skip_data_load=False)\n",
    "    pipelines.append(classifierModelPipeline)\n",
    "    classifierModelPipeline.model.to(device)\n",
    "    classifierModelPipeline.model.eval()\n",
    "    print(f\"Loaded model {classifierModelPipeline.config.model.description}\")\n",
    "    print(f\"Loaded model {config}\")\n",
    "    \n",
    "print(\"Done loading models\")\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "T, betas, alphas, alphas_cumprod, alphas_cumprod_prev, variance = get_forward_diffusion_params()\n",
    "alphas_cumprod = alphas_cumprod.to(device)\n",
    "\n",
    "for pipeline in tqdm(pipelines):\n",
    "    result_val = evaluate_unified_classifier_model(\n",
    "                    pipeline.model,\n",
    "                    (\n",
    "                        distiled_real_mu, \n",
    "                        distiled_real_lowess,\n",
    "                        distiled_mock_mu.data, \n",
    "                        distiled_mock_lowess.data\n",
    "                    ),\n",
    "                    alphas_cumprod,\n",
    "                    pipeline.config.training.timestep,\n",
    "                    pipeline.config.training.label_num,\n",
    "                    pipeline.config.training.label_count,\n",
    "                    pipeline.config.training.batch_size,\n",
    "                    predictCLS  \n",
    "                )\n",
    "    evaluation_results.append((pipeline.config.model.description, result_val, pipeline.config, pipeline.denoiser_model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Trained Conv Classifier\n",
    "\n",
    "conv_classifier_dict = torch.load(\"../checkpoints/classifier/conv_classifier.pth\")\n",
    "model = ConvChromoClassifier(seq_len=784, class_len=784)\n",
    "model.load_state_dict(conv_classifier_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "result_val = evaluate_unified_classifier_model(\n",
    "    model,\n",
    "    (\n",
    "        distiled_real_mu, \n",
    "        distiled_real_lowess,\n",
    "        distiled_mock_mu.data, \n",
    "        distiled_mock_lowess.data\n",
    "    ),\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    768,\n",
    "    512,\n",
    "    ConvPredictCLS  \n",
    ")\n",
    "\n",
    "evaluation_results.append((\"Conventional separate classifier\", result_val, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate zero shot unified classifier\n",
    "# load classifier, replace head with dummy head and run classification on cls 2.0\n",
    "# Method is N**2, may take 15mins to run, comment out whole cell if not needed\n",
    "\n",
    "classifier2ModelPipeline = ClassifierModelPipeline.load(\"unified_cls_attn_full_labels_denoiser_conv_4\", skip_data_load=False)\n",
    "# replace with empty CLS head, predictDenoise method will do the job instead of it\n",
    "classifier2ModelPipeline.model.classifier_head = ClassificationHeadDummy()\n",
    "classifier2ModelPipeline.model.to(device)\n",
    "classifier2ModelPipeline.model.eval()\n",
    "result_val = evaluate_unified_classifier_model(\n",
    "                    classifier2ModelPipeline.model,\n",
    "                    (\n",
    "                        distiled_real_mu, \n",
    "                        distiled_real_lowess,\n",
    "                        distiled_mock_mu.data, \n",
    "                        distiled_mock_lowess.data\n",
    "                    ),\n",
    "                    alphas_cumprod,\n",
    "                    450, # empirically, the best timestep for predictDenoise algorithm\n",
    "                    pipeline.config.training.label_num,\n",
    "                    pipeline.config.training.label_count,\n",
    "                    pipeline.config.training.batch_size,\n",
    "                    predictDenoise  \n",
    "                )\n",
    "# remove row with classifier 2.0\n",
    "evaluation_results = [x for x in evaluation_results if x[0] != \"Zero-shot unified classifier\"]\n",
    "evaluation_results.append((\"Zero-shot unified classifier\", result_val, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to pickle file\n",
    "os.makedirs(\"../metrics/results\", exist_ok=True)\n",
    "# get last timestamp\n",
    "timestamp_int = int(datetime.now().timestamp())\n",
    "result_filename = f\"../metrics/results/{timestamp_int}_results.pkl\"\n",
    "with open(result_filename, 'wb') as f:\n",
    "    pickle.dump(evaluation_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
