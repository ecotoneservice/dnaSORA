{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import panel as pn\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.preprocessing import ParsedChromoData, ParsedGData, ParsedGDataContainer, roman_numerals_inv, ChromoData, ChromoDataContainer\n",
    "\n",
    "\n",
    "\n",
    "hv.extension(\"plotly\")\n",
    "pn.extension(\"plotly\")\n",
    "pn.config.theme = 'dark'\n",
    "hv.renderer('plotly').theme = 'dark'\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for data processing\n",
    "\n",
    "# Parses chromosome data\n",
    "def loader(G_number, fold=\"RD_cache\"):\n",
    "    # Load the data\n",
    "    Gxx_df = pd.read_csv(f\"{fold}/{G_number}.txt\", sep=\"\\t\", header=0)\n",
    "    Gxx_df[['sample1', 'new_col']] = Gxx_df['sample1'].str.split(',', expand=True).astype(np.int64)\n",
    "    Gxx_df.columns = ['CHROM', 'POS', 'Alt_Count', 'Ref_Count']\n",
    "    Gxx_df['Read_Depth'] = Gxx_df['Alt_Count'] + Gxx_df['Ref_Count']\n",
    "    Gxx_df['Gxx_ratio'] = 1 - (Gxx_df['Ref_Count'] / Gxx_df['Read_Depth'])  # CAN revert here to make consistent with plant biologists\n",
    "\n",
    "    # Separate data by chromosomes and clean\n",
    "    xI = Gxx_df.loc[Gxx_df['CHROM'] == 'chrI'].sort_values(by=['POS']).drop_duplicates(['POS'], keep='first')\n",
    "    xII = Gxx_df.loc[Gxx_df['CHROM'] == 'chrII'].sort_values(by=['POS']).drop_duplicates(['POS'], keep='first')\n",
    "    xIII = Gxx_df.loc[Gxx_df['CHROM'] == 'chrIII'].sort_values(by=['POS']).drop_duplicates(['POS'], keep='first')\n",
    "    xIV = Gxx_df.loc[Gxx_df['CHROM'] == 'chrIV'].sort_values(by=['POS']).drop_duplicates(['POS'], keep='first')\n",
    "    xV = Gxx_df.loc[Gxx_df['CHROM'] == 'chrV'].sort_values(by=['POS']).drop_duplicates(['POS'], keep='first')\n",
    "    xX = Gxx_df.loc[Gxx_df['CHROM'] == 'chrX'].sort_values(by=['POS']).drop_duplicates(['POS'], keep='first')\n",
    "\n",
    "    # Concatenate all data\n",
    "    xALL = pd.concat([xI, xII, xIII, xIV, xV, xX], axis=0, ignore_index=True)\n",
    "    xALL.reset_index(drop=True, inplace=True)\n",
    "    xALL['gPOS'] = xALL.index  # Create global pan chromosome index number\n",
    "    xALL = xALL[['gPOS', 'CHROM', 'POS', 'Alt_Count', 'Ref_Count', 'Read_Depth', 'Gxx_ratio']]\n",
    "\n",
    "    # Set binary threshold\n",
    "    Hawaiian_threshold = 0.9\n",
    "\n",
    "    # Generate binary column\n",
    "    xALL_binary = xALL[['gPOS', 'CHROM', 'POS', 'Gxx_ratio', 'Read_Depth', 'Alt_Count', 'Ref_Count']]\n",
    "    xALL_binary['Gxx_ratio_binary'] = np.where(xALL_binary['Gxx_ratio'] >= Hawaiian_threshold, 1, 0)\n",
    "\n",
    "    return xI, xII, xIII, xIV, xV, xX, xALL, xALL_binary, [xI, xII, xIII, xIV, xV, xX]\n",
    "\n",
    "# grouping data by G number into serialisable data containers\n",
    "def ParsedData_processing(performReprocessing=False):\n",
    "    parsed_data_file_exists = os.path.exists('../data/preprocessed/processed_data.pkl')\n",
    "    print(f\"Parsed data file exists: {parsed_data_file_exists}\")\n",
    "    if performReprocessing or not parsed_data_file_exists:\n",
    "        # Preprocessing, ranging gausian/non gaussian data\n",
    "        os.makedirs('../data/preprocessed', exist_ok=True)\n",
    "        \n",
    "        # enumerate all txt files in directory\n",
    "        txt_files = [f for f in os.listdir('RD_cache') if f.endswith('.txt')]\n",
    "        data_arr = []\n",
    "\n",
    "        for txt_file in tqdm(txt_files):\n",
    "            G_number_str = txt_file.split('.')[0]\n",
    "            xI, xII, xIII, xIV, xV, xX, xALL, xALL_binary, xARR = loader(G_number_str)\n",
    "            arrs = [xI, xII, xIII, xIV, xV, xX]\n",
    "            g_number_data = ParsedGData(G_number_str)\n",
    "            for i in range(len(arrs)):\n",
    "                chrom = roman_numerals_inv[i + 1]\n",
    "                arr = arrs[i]\n",
    "                g_number_data.add_parsed_chromo_data(ParsedChromoData(chrom, i + 1, arr))\n",
    "            data_arr.append(g_number_data)\n",
    "                \n",
    "        # order arrays by G number\n",
    "        data_arr.sort(key=lambda x: int(re.search(r'\\d+', x.g_number).group()), reverse=True)\n",
    "        parsed_data_instance = ParsedGDataContainer()\n",
    "        parsed_data_instance.data = data_arr\n",
    "        parsed_data_instance.save_to_pkl()\n",
    "        return parsed_data_instance\n",
    "    else:\n",
    "        return ParsedGDataContainer.load_from_pkl()\n",
    "\n",
    "# Process the data, calculate lowess, find max index, and sort into gausian and non gausian data by data from the overrides, overrides defined manually in external json file\n",
    "def GaussianData_processing(parsed_data_instance, overrides={}, lowess_iter=3, performReprocessing=False):\n",
    "    gausian_data_file_exists = os.path.exists('../data/preprocessed/gaussian_data.pkl')\n",
    "    print(f\"Gaussian data file exists: {gausian_data_file_exists}\")\n",
    "    if performReprocessing or not gausian_data_file_exists:\n",
    "\n",
    "        gausians = []\n",
    "        not_gausians = []\n",
    "        map = {}\n",
    "\n",
    "        for g_container in tqdm(parsed_data_instance.data):\n",
    "            \n",
    "            map[g_container.g_number] = []\n",
    "            \n",
    "            for chromo_data in g_container.parsed_chromo_data:\n",
    "                \n",
    "                G_number = g_container.g_number\n",
    "                chrom = chromo_data.chrom_label\n",
    "                arr = chromo_data.array\n",
    "                \n",
    "                # calculate lowess curve (for visualisations) and lowess maximum (for prediction measurements)\n",
    "                \n",
    "                lowess_result = sm.nonparametric.lowess(arr['Gxx_ratio'], arr['POS'], frac=0.6, it=lowess_iter, return_sorted=True)\n",
    "                lowess_x, lowess_y = lowess_result.T\n",
    "                max_idx = np.argmax(lowess_y)\n",
    "                lowess_out = np.array([lowess_x, lowess_y]).T\n",
    "                \n",
    "                # if in overrides, use the is_gausian value, else - this chromo is not gaussian                \n",
    "                is_gausian_overrided = overrides.get(G_number, {}).get(chrom, {}).get('is_gausian', None)\n",
    "                \n",
    "                # if mu in overrides, it means it is measured experimentally and we have to store it for future evaluation of the model\n",
    "                m_index = None\n",
    "                m_overrided = overrides.get(G_number, {}).get(chrom, {}).get('m', None)\n",
    "                if m_overrided is not None:\n",
    "                    # Calculate the absolute difference and find the index of the minimum value\n",
    "                    m_index = np.argmin(np.abs(arr['POS'] - m_overrided))\n",
    "                    m_rd = arr['POS'].iloc[m_index]\n",
    "                    print(f'G number: {G_number}, chrom: {chrom}, m_overrided: {m_overrided}, m_rd: {m_rd}, m_delta: {np.abs(arr[\"POS\"] - m_overrided).min()}')\n",
    "                    print(f\"Len of arr: {len(arr['POS'])}, m_index: {m_index}, Min POS and max POS: {arr['POS'].min()}, {arr['POS'].max()}, m_overrided: {m_overrided}\")\n",
    "                    \n",
    "                # add to arrays\n",
    "                # GN, chrom, arr, is_gausian, measured µ\n",
    "            \n",
    "                chromoData = ChromoData(G_number, chrom, chromo_data.i_number, arr, lowess_out, max_idx, is_gausian_overrided, m_index)\n",
    "                \n",
    "                if is_gausian_overrided:\n",
    "                    gausians.append(chromoData)\n",
    "                else:\n",
    "                    not_gausians.append(chromoData)\n",
    "                    \n",
    "                map[G_number].append(chromoData)\n",
    "            \n",
    "            # sort map[GN] by chromo number\n",
    "            \n",
    "            map[G_number].sort(key=lambda x: x.i_number)\n",
    "                    \n",
    "        \n",
    "                \n",
    "            \n",
    "        gausian_data = ChromoDataContainer()\n",
    "        gausian_data.gausians = gausians\n",
    "        gausian_data.not_gausians = not_gausians\n",
    "        gausian_data.all = gausians + not_gausians\n",
    "        gausian_data.map = map\n",
    "        gausian_data.save_to_pkl()\n",
    "        print(\"Saved gausian data\")\n",
    "        return gausian_data\n",
    "    else:\n",
    "        return ChromoDataContainer.load_from_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform processing\n",
    "# it will save hierarchical unprocessed data structures\n",
    "# it will save processed data structures to another file\n",
    "\n",
    "# laoding overrides for gausian data. Overrides are used to manually set if the data is gausian or not, and to set the m index for measuered µ\n",
    "print(\"Loading overrides\")\n",
    "gausian_overrides = json.loads(open('../configs/preprocessing/gausian_overrides.json').read())\n",
    "\n",
    "# perform initial data parsing\n",
    "print(\"Performing data parsing\")\n",
    "parsed_data_instance = ParsedData_processing()\n",
    "\n",
    "# perform gausian data processing\n",
    "print(\"Performing gausian data processing\")\n",
    "gausian_data_instance = GaussianData_processing(parsed_data_instance, overrides=gausian_overrides, lowess_iter=5)\n",
    "\n",
    "# check if data is loaded correctly\n",
    "parsed_data_arr_len = len(parsed_data_instance.data)\n",
    "data_arr_len = len(parsed_data_instance.data)\n",
    "        \n",
    "print(f\"Number of gausians: {len(gausian_data_instance.gausians)}, Number of not gausians: {len(gausian_data_instance.not_gausians)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell visualizes parsed and processed data\n",
    "# Expect that manually set gausian property should correspond to the color (yellow: true, red: false). Lowes data and max index should be visible and meaningful\n",
    "\n",
    "# calculate average mean and std of Gxx_ratio from gausians\n",
    "gausian_means_pos = []\n",
    "gausian_stds_pos = []\n",
    "pos_mins_pos = []\n",
    "pos_maxs_pos = []\n",
    "\n",
    "gausian_means_gxx = []\n",
    "gausian_stds_gxx = []\n",
    "pos_mins_gxx = []\n",
    "pos_maxs_gxx = []\n",
    "\n",
    "# for arr in datasets['plain_gausian_train']:\n",
    "for g_container in tqdm(parsed_data_instance.data):\n",
    "    \n",
    "    for chromo_data in g_container.parsed_chromo_data:\n",
    "        \n",
    "        G_number = g_container.g_number\n",
    "        chrom = chromo_data.chrom_label\n",
    "        arr = chromo_data.array\n",
    "        gausian_means_pos.append(arr['POS'].mean())\n",
    "        gausian_stds_pos.append(arr['POS'].std())\n",
    "        pos_mins_pos.append(arr['POS'].min())\n",
    "        pos_maxs_pos.append(arr['POS'].max())\n",
    "        \n",
    "        gausian_means_gxx.append(arr['Gxx_ratio'].mean())\n",
    "        gausian_stds_gxx.append(arr['Gxx_ratio'].std())\n",
    "        pos_mins_gxx.append(arr['Gxx_ratio'].min())\n",
    "        pos_maxs_gxx.append(arr['Gxx_ratio'].max())\n",
    "    \n",
    "pos_gausian_mean_avg = np.average(gausian_means_pos)\n",
    "pos_gausian_std_avg = np.average(gausian_stds_pos)\n",
    "pos_min = int(np.average(pos_mins_pos))\n",
    "pos_max = int(np.average(pos_maxs_pos))\n",
    "\n",
    "gxx_gausian_mean_avg = np.average(gausian_means_gxx)\n",
    "gxx_gausian_std_avg = np.average(gausian_stds_gxx)\n",
    "gxx_min = np.average(pos_mins_gxx)\n",
    "gxx_max = np.average(pos_maxs_gxx)\n",
    "\n",
    "print(f\"POS Gausian mean avg: {pos_gausian_mean_avg}, std avg: {pos_gausian_std_avg}, min avg: {pos_min}, max avg: {pos_max}\")\n",
    "print(f\"Gxx_ratio Gausian mean avg: {gxx_gausian_mean_avg}, std avg: {gxx_gausian_std_avg}, min avg: {gxx_min}, max avg: {gxx_max}\")\n",
    "\n",
    "# plot graphs    \n",
    "    \n",
    "fig_root, axes_root = plt.subplots(data_arr_len, 6, figsize=(40, data_arr_len * 5))\n",
    "fig_root.suptitle('Distributions', fontsize=16)\n",
    "for i, (key, data) in enumerate(gausian_data_instance.map.items()):\n",
    "    for k, g in enumerate(data):\n",
    "    \n",
    "        G_number = g.g_number\n",
    "        chrom = g.chrom_label\n",
    "        arr = g.array\n",
    "        lowess_out = g.lowess_out\n",
    "        max_idx = g.lowess_max_idx\n",
    "        is_gausian = g.is_gausian\n",
    "        m_index = g.m_index\n",
    "    \n",
    "        ax = axes_root[i, k]\n",
    "            \n",
    "        sb = sns.scatterplot(x='POS', y='Gxx_ratio', data=arr, c='grey', ax=ax)        \n",
    "        sb.set_title(f\"{chrom} - {G_number}\")\n",
    "        \n",
    "        sb.set_xlabel(f'gausian={is_gausian}')\n",
    "        sb.set_ylabel('')\n",
    "        \n",
    "        # hide ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        # add lowess_out as a chart, x is POS, y is lowess_out\n",
    "        ax.plot(arr['POS'], lowess_out[:, 1], 'r-', linewidth=2)\n",
    "        # add max value as a tringle point\n",
    "        \n",
    "        # closest POS value to max_idx\n",
    "        max_pos_rd = arr['POS'].iloc[max_idx]\n",
    "        \n",
    "        # put point , big size\n",
    "        # ax.plot(max_pos, arr['Gxx_ratio'].iloc[max_idx], 'g^', markersize=10)\n",
    "\n",
    "        # put vertical line on max point\n",
    "        ax.axvline(max_pos_rd, color='b', linestyle='--')\n",
    "        \n",
    "        # put vertical line on half of POS\n",
    "        \n",
    "        middle_pos = arr['POS'].iloc[-1] / 2\n",
    "        ax.axvline(middle_pos, color='r', linestyle='--')\n",
    "        \n",
    "        ax.set_title(chrom)\n",
    "        # bg color is weak green if gausian, weak red if not\n",
    "        ax.set_facecolor(\n",
    "            (0.9764705882352941, 0.984313725490196, 0.9058823529411765, 1) \n",
    "            if is_gausian \n",
    "            else (0.984313725490196, 0.9137254901960784, 0.9058823529411765, 1))\n",
    "            \n",
    "        axes_root[i, 0].set_ylabel(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
